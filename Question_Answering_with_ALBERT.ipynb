{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering with ALBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPokPffBGScvrFJ7E6kD/9s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "814460e6c2ea47fd9d0f10ea0bdfa5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b61b9db26d2435c950dac4efaaa5110",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd7e54b1368346a29e1b963b6b410df2",
              "IPY_MODEL_0df477b5255d4bb18305cb27d1dd72b9"
            ]
          }
        },
        "7b61b9db26d2435c950dac4efaaa5110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd7e54b1368346a29e1b963b6b410df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70b0ff61b96d433b831b15ceccae702d",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1114,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1114,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97187d875ed84185a938a9a983cf4fc8"
          }
        },
        "0df477b5255d4bb18305cb27d1dd72b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9e002990e3a44de86579377f9fe24f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1.11k/1.11k [00:00&lt;00:00, 57.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_714017c3802f4b4c97b46843000a38b2"
          }
        },
        "70b0ff61b96d433b831b15ceccae702d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97187d875ed84185a938a9a983cf4fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9e002990e3a44de86579377f9fe24f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "714017c3802f4b4c97b46843000a38b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e53e5b79e1fa460fad9e8c2f41bcacaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50759731043349f6bdc38656c25efa46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ac52bdfe27f4600b5b48a37fe608908",
              "IPY_MODEL_9169a9b8d6974aa8ab759d9b8dbbbba1"
            ]
          }
        },
        "50759731043349f6bdc38656c25efa46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ac52bdfe27f4600b5b48a37fe608908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_616193b0be9c4177b3df480b7205e9ef",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab6f1b08894145c59eecdb63fd4efc24"
          }
        },
        "9169a9b8d6974aa8ab759d9b8dbbbba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63c9766c59324c32899e6a0ddd9dcd39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 760k/760k [00:01&lt;00:00, 699kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0b013efa73945a4abdbe13101596e29"
          }
        },
        "616193b0be9c4177b3df480b7205e9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab6f1b08894145c59eecdb63fd4efc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63c9766c59324c32899e6a0ddd9dcd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0b013efa73945a4abdbe13101596e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f522afc051ab4e98aaa7444592a1d98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f1526b1dd324118b4faff49132fc646",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63e48b35866d4b05a9cce5549b392a88",
              "IPY_MODEL_464ba8f4d6814f198c0971f64254ca53"
            ]
          }
        },
        "8f1526b1dd324118b4faff49132fc646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63e48b35866d4b05a9cce5549b392a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3363a1685344020ba3442bda67fa0d3",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 234922444,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 234922444,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1a6393f5c8c4d10b67498e51a64ec55"
          }
        },
        "464ba8f4d6814f198c0971f64254ca53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7cb247067664b1498d79ee320d359e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 235M/235M [00:20&lt;00:00, 11.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db4997c677084a8bb1fe8d0f921bcaff"
          }
        },
        "b3363a1685344020ba3442bda67fa0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1a6393f5c8c4d10b67498e51a64ec55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7cb247067664b1498d79ee320d359e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db4997c677084a8bb1fe8d0f921bcaff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spark-ming/albert-qa-demo/blob/master/Question_Answering_with_ALBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qfQAtRsMVl7",
        "colab_type": "text"
      },
      "source": [
        "# Reading Comprehension with ALBERT (and similar)\n",
        "\n",
        "Author: [@techno246](https://twitter.com/techno246)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Reading comprehension, otherwise known as Question Answer systems, are one of the tasks that NLP tries to solve. The goal of this task is to be able to answer an arbitary question given a context. For instance, given the following context:\n",
        "\n",
        "> New Zealand (Māori: Aotearoa) is a sovereign island country in the southwestern Pacific Ocean. The country has two main landmasses — the North Island (Te Ika-a-Māui), and the South Island (Te Waipounamu) — and around 600 smaller islands. It has a total land area of 268,000 square kilometres (103,500 sq mi), and a population of 4.9 million.  Because of its remoteness, it was one of the last lands to be settled by humans. During its long period of isolation, New Zealand developed a distinct biodiversity of animal, fungal, and plant life. The country's varied topography and its sharp mountain peaks, such as the Southern Alps, owe much to the tectonic uplift of land and volcanic eruptions. New Zealand's capital city is Wellington, and its most populous city is Auckland.\n",
        "\n",
        "We ask the question\n",
        "\n",
        "> What is the capital of New Zealand? \n",
        "\n",
        "We expect the QA system is to respond with something like this:\n",
        "\n",
        "> Wellington\n",
        "\n",
        "Since 2017, transformer models have shown to outperform existing approaches for this task. Many variations of transformer models exist, including BERT, RoBERTA, XLNET. One of the newcomers to the group is ALBERT (A Lite BERT) which was published in September 2019. The research group claims that it outperforms BERT, with much less parameters (shorter training and inference time). \n",
        "\n",
        "This tutorial demonstrates how you can fine-tune a transformer model for the task of QnA and use it for inference. For this tutorial, we will use the transformer library built by Hugging Face, which is an extremely nice implementation of the transformer models (including ALBERT) in both TensorFlow and PyTorch. You can also just download a fine tuned model [here](https://huggingface.co/models) (which I encourage in general to save money and reduce emissions), however for educational purposes we will train a small version ourselves. \n",
        "\n",
        "Note that the goal of this is not to build an optimised, production ready system, but to demonstrate the concept with as little code as possible. Therefore a lot of code will be retrofitted for this purpose. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBBHbGvQN5vX",
        "colab_type": "text"
      },
      "source": [
        "## 1.0 Setup\n",
        "\n",
        "If you're going to train your own model, you're going to need som RAM. If not, skip this step\n",
        "\n",
        "Here's a hack: you can crash our notebook instance to get some more RAM (25GB instead of default 12GB). Trust me, it works. When the runtime crashes, it will ask you if you want more RAM. Just press yes.\n",
        "\n",
        "Note **don't run this a second time**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2FGL3dFafpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "10d27d33-3c13-41a4-ec45-e8052d5aa6dd"
      },
      "source": [
        "# Colab Hack\n",
        "a = ['crash me']\n",
        "while(1):\n",
        "    a = a + a"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-61bfa5bc4c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'crash me'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZOx-qM0cRUX",
        "colab_type": "text"
      },
      "source": [
        "Let's check out what kind of GPU our friends at Google gave us. Hope it's a P100!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frTeTcy4WdbY",
        "colab_type": "code",
        "outputId": "fa494920-3766-465c-f9c2-e97351bd8ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jan 20 11:53:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5RImM3oWbrZ",
        "colab_type": "text"
      },
      "source": [
        "First, we copy over the Github.\n",
        "\n",
        "\n",
        "Note it's checking out a specific commit only because I've tested this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOAoUwBFMQCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\n",
        "&& cd transformers \\\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRZned-8WJrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ./transformers\n",
        "!pip install tensorboardX --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHCuzhPptH0M",
        "colab_type": "text"
      },
      "source": [
        "## 2.0 Train Model\n",
        "\n",
        "This is where we can train our own model. Note you can skip this step if you don't want to wait 1.5 hours!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaQGsAiWXcnd",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Get Training and Evaluation Data\n",
        "\n",
        "The SQuAD dataset contains question/answer pairs to for training the ALBERT model for the QA task. \n",
        "\n",
        "Now get the SQuAD V2.0 dataset. `train-v2.0.json` is for training and `dev-v2.0.json` is for evaluation to see how well your model trained.\n",
        "\n",
        "Read more about this dataset here: https://rajpurkar.github.io/SQuAD-explorer/\n",
        "\n",
        "[Albert Learns to Read](https://littlealbert.now.sh) is trained on SQuAD V2.0. I'm using V1.1 in this demo because it keeps crashing the Colab runtime (runs out of memory). To train against 2.0 on your own machine, just change \"1.1\" to \"2.0\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI6e-PfOXSnO",
        "colab_type": "code",
        "outputId": "77e6ee18-c7f1-4770-bd4c-e2736f84092f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "!mkdir dataset \\\n",
        "&& cd dataset \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-20 11:08:54--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.108.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M  24.8MB/s    in 1.6s    \n",
            "\n",
            "2020-01-20 11:08:58 (24.8 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2020-01-20 11:08:58--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.108.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  6.53MB/s    in 0.6s    \n",
            "\n",
            "2020-01-20 11:08:59 (6.53 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ87q93GDeeL",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Run training \n",
        "\n",
        "We can now train the model with the training set. \n",
        "\n",
        "### Notes about parameters:\n",
        "`per_gpu_train_batch_size` specifies the number of training examples per iteration per GPU. *In general*, higher means more accuracy and faster training. However, the biggest limitation is the size of the GPU. 12 is what I use for a GPU with 16GB memory. \n",
        "\n",
        "`save_steps` specifies number of steps before it outputs a checkpoint file. I've increased it to save disk space.\n",
        "\n",
        "`num_train_epochs` I recommend two epochs here. It's currently set to one for the purpose of time\n",
        "\n",
        "Warning: it takes about 1.5 hours to train an epoch! If you don't want to wait this long, feel free to skip this step and note the comment in the code to use a pretrained model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Eg53t3QXZAb",
        "colab_type": "code",
        "outputId": "ff767f2c-48c3-42b1-e3c5-4964f8ed013e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!export SQUAD_DIR=/content/dataset \\\n",
        "&& python transformers/examples/run_squad.py \\\n",
        "  --model_type albert \\\n",
        "  --model_name_or_path albert-base-v2 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_lower_case \\\n",
        "  --train_file $SQUAD_DIR/train-v2.0.json \\\n",
        "  --predict_file $SQUAD_DIR/dev-v2.0.json \\\n",
        "  --per_gpu_train_batch_size 12 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 1.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir /content/model_output \\\n",
        "  --save_steps 1000 \\\n",
        "  --threads 4 \\\n",
        "  --version_2_with_negative "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/20/2020 11:09:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "01/20/2020 11:09:08 - INFO - filelock -   Lock 139840643170256 acquired on /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505.lock\n",
            "01/20/2020 11:09:08 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpcnlc359m\n",
            "Downloading: 100% 483/483 [00:00<00:00, 443kB/s]\n",
            "01/20/2020 11:09:09 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json in cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505\n",
            "01/20/2020 11:09:09 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505\n",
            "01/20/2020 11:09:09 - INFO - filelock -   Lock 139840643170256 released on /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505.lock\n",
            "01/20/2020 11:09:09 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-config.json from cache at /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.ea38adf566af403b92e06f53ac1b443ebd324162fc74a90de95609963d429505\n",
            "01/20/2020 11:09:09 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "01/20/2020 11:09:10 - INFO - filelock -   Lock 139840273436624 acquired on /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf.lock\n",
            "01/20/2020 11:09:10 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpahj4xsjl\n",
            "Downloading: 100% 760k/760k [00:00<00:00, 826kB/s]\n",
            "01/20/2020 11:09:12 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model in cache at /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
            "01/20/2020 11:09:12 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
            "01/20/2020 11:09:12 - INFO - filelock -   Lock 139840273436624 released on /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf.lock\n",
            "01/20/2020 11:09:12 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model from cache at /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
            "01/20/2020 11:09:12 - INFO - filelock -   Lock 139840273436624 acquired on /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24.lock\n",
            "01/20/2020 11:09:12 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_2zrhz6s\n",
            "Downloading: 100% 47.4M/47.4M [00:04<00:00, 10.1MB/s]\n",
            "01/20/2020 11:09:18 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin in cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "01/20/2020 11:09:18 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "01/20/2020 11:09:18 - INFO - filelock -   Lock 139840273436624 released on /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24.lock\n",
            "01/20/2020 11:09:18 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-pytorch_model.bin from cache at /root/.cache/torch/transformers/a175de1d3c60bba6e74bd034c02a34d909d9f36a0cf472b02301c8790ba44834.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24\n",
            "01/20/2020 11:09:18 - INFO - transformers.modeling_utils -   Weights of AlbertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "01/20/2020 11:09:18 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "01/20/2020 11:09:27 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=3e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=384, max_steps=-1, model_name_or_path='albert-base-v2', model_type='albert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=1.0, output_dir='/content/model_output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=12, predict_file='/content/dataset/dev-v2.0.json', save_steps=1000, seed=42, server_ip='', server_port='', threads=4, tokenizer_name='', train_file='/content/dataset/train-v2.0.json', verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)\n",
            "01/20/2020 11:09:27 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 442/442 [00:41<00:00, 10.62it/s]\n",
            "convert squad examples to features: 100% 130319/130319 [05:31<00:00, 392.84it/s]\n",
            "add example index and unique id: 100% 130319/130319 [00:00<00:00, 864184.41it/s]\n",
            "01/20/2020 11:15:45 - INFO - __main__ -   Saving features into cached file ./cached_train_albert-base-v2_384\n",
            "tcmalloc: large alloc 1178640384 bytes == 0x7f2cc747a000 @  0x7f2fc2b932a4 0x592727 0x4dddf7 0x4e2667 0x4e3109 0x4e30d0 0x4e14d8 0x4e2c5b 0x4e29eb 0x4e3024 0x4e3ac6 0x5ebdc2 0x50a94c 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080\n",
            "tcmalloc: large alloc 1767956480 bytes == 0x7f2c1b82c000 @  0x7f2fc2b932a4 0x592727 0x4e10c9 0x4e24c0 0x4e2acf 0x4e307c 0x4e14d8 0x4e2c5b 0x4e29bf 0x4e30d0 0x4e3ac6 0x5ebdc2 0x50a94c 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50a080 0x50aa7d 0x50c5b9 0x508245 0x50a080\n",
            "01/20/2020 11:19:25 - INFO - __main__ -   ***** Running training *****\n",
            "01/20/2020 11:19:25 - INFO - __main__ -     Num examples = 132198\n",
            "01/20/2020 11:19:25 - INFO - __main__ -     Num Epochs = 1\n",
            "01/20/2020 11:19:25 - INFO - __main__ -     Instantaneous batch size per GPU = 12\n",
            "01/20/2020 11:19:25 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 12\n",
            "01/20/2020 11:19:25 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "01/20/2020 11:19:25 - INFO - __main__ -     Total optimization steps = 11017\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/11017 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/11017 [00:01<5:56:39,  1.94s/it]\u001b[A\n",
            "Iteration:   0% 2/11017 [00:02<4:35:56,  1.50s/it]\u001b[A\n",
            "Iteration:   0% 3/11017 [00:02<3:39:23,  1.20s/it]\u001b[A\n",
            "Iteration:   0% 4/11017 [00:03<2:59:52,  1.02it/s]\u001b[A\n",
            "Iteration:   0% 5/11017 [00:03<2:32:09,  1.21it/s]\u001b[A\n",
            "Iteration:   0% 6/11017 [00:04<2:12:50,  1.38it/s]\u001b[A\n",
            "Iteration:   0% 7/11017 [00:04<1:59:16,  1.54it/s]\u001b[A\n",
            "Iteration:   0% 8/11017 [00:05<1:49:51,  1.67it/s]\u001b[A\n",
            "Iteration:   0% 9/11017 [00:05<1:43:15,  1.78it/s]\u001b[A\n",
            "Iteration:   0% 10/11017 [00:06<1:38:35,  1.86it/s]\u001b[A\n",
            "Iteration:   0% 11/11017 [00:06<1:35:33,  1.92it/s]\u001b[A\n",
            "Iteration:   0% 12/11017 [00:07<1:33:07,  1.97it/s]\u001b[A\n",
            "Iteration:   0% 13/11017 [00:07<1:31:30,  2.00it/s]\u001b[A\n",
            "Iteration:   0% 14/11017 [00:08<1:30:15,  2.03it/s]\u001b[A\n",
            "Iteration:   0% 15/11017 [00:08<1:29:26,  2.05it/s]\u001b[A\n",
            "Iteration:   0% 16/11017 [00:09<1:28:54,  2.06it/s]\u001b[A\n",
            "Iteration:   0% 17/11017 [00:09<1:28:33,  2.07it/s]\u001b[A\n",
            "Iteration:   0% 18/11017 [00:10<1:28:16,  2.08it/s]\u001b[A\n",
            "Iteration:   0% 19/11017 [00:10<1:28:02,  2.08it/s]\u001b[A\n",
            "Iteration:   0% 20/11017 [00:11<1:27:59,  2.08it/s]\u001b[A\n",
            "Iteration:   0% 21/11017 [00:11<1:27:51,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 22/11017 [00:11<1:27:48,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 23/11017 [00:12<1:27:47,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 24/11017 [00:12<1:27:42,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 25/11017 [00:13<1:27:36,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 26/11017 [00:13<1:27:34,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 27/11017 [00:14<1:27:29,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 28/11017 [00:14<1:27:27,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 29/11017 [00:15<1:27:26,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 30/11017 [00:15<1:27:26,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 31/11017 [00:16<1:27:28,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 32/11017 [00:16<1:27:28,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 33/11017 [00:17<1:27:27,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 34/11017 [00:17<1:27:28,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 35/11017 [00:18<1:27:30,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 36/11017 [00:18<1:27:29,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 37/11017 [00:19<1:27:23,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 38/11017 [00:19<1:27:27,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 39/11017 [00:20<1:27:24,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 40/11017 [00:20<1:27:24,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 41/11017 [00:21<1:27:25,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 42/11017 [00:21<1:27:25,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 43/11017 [00:22<1:27:22,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 44/11017 [00:22<1:27:16,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 45/11017 [00:22<1:27:16,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 46/11017 [00:23<1:27:16,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 47/11017 [00:23<1:27:12,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 48/11017 [00:24<1:27:13,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 49/11017 [00:24<1:27:16,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 50/11017 [00:25<1:27:12,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 51/11017 [00:25<1:27:13,  2.10it/s]\u001b[A\n",
            "Iteration:   0% 52/11017 [00:26<1:27:14,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 53/11017 [00:26<1:27:17,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 54/11017 [00:27<1:27:22,  2.09it/s]\u001b[A\n",
            "Iteration:   0% 55/11017 [00:27<1:27:26,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 56/11017 [00:28<1:27:25,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 57/11017 [00:28<1:27:17,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 58/11017 [00:29<1:27:21,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 59/11017 [00:29<1:27:21,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 60/11017 [00:30<1:27:18,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 61/11017 [00:30<1:27:20,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 62/11017 [00:31<1:27:17,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 63/11017 [00:31<1:27:11,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 64/11017 [00:32<1:27:09,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 65/11017 [00:32<1:27:10,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 66/11017 [00:33<1:27:06,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 67/11017 [00:33<1:27:05,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 68/11017 [00:33<1:27:05,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 69/11017 [00:34<1:27:02,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 70/11017 [00:34<1:26:58,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 71/11017 [00:35<1:27:03,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 72/11017 [00:35<1:27:08,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 73/11017 [00:36<1:27:07,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 74/11017 [00:36<1:27:05,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 75/11017 [00:37<1:27:10,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 76/11017 [00:37<1:27:06,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 77/11017 [00:38<1:27:02,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 78/11017 [00:38<1:27:02,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 79/11017 [00:39<1:27:02,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 80/11017 [00:39<1:27:01,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 81/11017 [00:40<1:27:01,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 82/11017 [00:40<1:27:07,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 83/11017 [00:41<1:27:00,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 84/11017 [00:41<1:26:59,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 85/11017 [00:42<1:27:07,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 86/11017 [00:42<1:27:00,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 87/11017 [00:43<1:26:59,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 88/11017 [00:43<1:26:58,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 89/11017 [00:43<1:26:57,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 90/11017 [00:44<1:26:55,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 91/11017 [00:44<1:26:55,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 92/11017 [00:45<1:27:01,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 93/11017 [00:45<1:26:58,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 94/11017 [00:46<1:26:56,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 95/11017 [00:46<1:27:03,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 96/11017 [00:47<1:26:56,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 97/11017 [00:47<1:26:52,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 98/11017 [00:48<1:27:04,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 99/11017 [00:48<1:27:02,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 100/11017 [00:49<1:26:58,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 101/11017 [00:49<1:26:56,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 102/11017 [00:50<1:27:01,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 103/11017 [00:50<1:27:00,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 104/11017 [00:51<1:27:04,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 105/11017 [00:51<1:26:59,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 106/11017 [00:52<1:26:59,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 107/11017 [00:52<1:27:02,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 108/11017 [00:53<1:27:01,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 109/11017 [00:53<1:26:53,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 110/11017 [00:54<1:26:53,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 111/11017 [00:54<1:26:49,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 112/11017 [00:54<1:26:44,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 113/11017 [00:55<1:26:41,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 114/11017 [00:55<1:26:47,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 115/11017 [00:56<1:26:49,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 116/11017 [00:56<1:26:49,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 117/11017 [00:57<1:26:47,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 118/11017 [00:57<1:26:44,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 119/11017 [00:58<1:26:45,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 120/11017 [00:58<1:26:43,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 121/11017 [00:59<1:26:52,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 122/11017 [00:59<1:26:47,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 123/11017 [01:00<1:26:44,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 124/11017 [01:00<1:26:40,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 125/11017 [01:01<1:26:36,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 126/11017 [01:01<1:26:40,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 127/11017 [01:02<1:26:38,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 128/11017 [01:02<1:26:35,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 129/11017 [01:03<1:26:37,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 130/11017 [01:03<1:26:37,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 131/11017 [01:04<1:26:33,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 132/11017 [01:04<1:26:30,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 133/11017 [01:05<1:26:31,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 134/11017 [01:05<1:26:32,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 135/11017 [01:05<1:26:36,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 136/11017 [01:06<1:26:51,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 137/11017 [01:06<1:26:45,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 138/11017 [01:07<1:26:43,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 139/11017 [01:07<1:26:42,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 140/11017 [01:08<1:26:34,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 141/11017 [01:08<1:26:32,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 142/11017 [01:09<1:26:30,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 143/11017 [01:09<1:26:30,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 144/11017 [01:10<1:26:34,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 145/11017 [01:10<1:26:35,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 146/11017 [01:11<1:26:32,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 147/11017 [01:11<1:26:27,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 148/11017 [01:12<1:26:28,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 149/11017 [01:12<1:26:26,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 150/11017 [01:13<1:26:31,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 151/11017 [01:13<1:26:33,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 152/11017 [01:14<1:26:29,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 153/11017 [01:14<1:26:27,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 154/11017 [01:15<1:26:24,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 155/11017 [01:15<1:26:22,  2.10it/s]\u001b[A\n",
            "Iteration:   1% 156/11017 [01:15<1:26:25,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 157/11017 [01:16<1:26:23,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 158/11017 [01:16<1:26:24,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 159/11017 [01:17<1:26:29,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 160/11017 [01:17<1:26:28,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 161/11017 [01:18<1:26:27,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 162/11017 [01:18<1:26:22,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 163/11017 [01:19<1:26:28,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 164/11017 [01:19<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   1% 165/11017 [01:20<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 166/11017 [01:20<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 167/11017 [01:21<1:26:28,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 168/11017 [01:21<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 169/11017 [01:22<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 170/11017 [01:22<1:26:28,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 171/11017 [01:23<1:26:23,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 172/11017 [01:23<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 173/11017 [01:24<1:26:26,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 174/11017 [01:24<1:26:22,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 175/11017 [01:25<1:26:17,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 176/11017 [01:25<1:26:14,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 177/11017 [01:26<1:26:12,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 178/11017 [01:26<1:26:15,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 179/11017 [01:26<1:26:12,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 180/11017 [01:27<1:26:14,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 181/11017 [01:27<1:26:17,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 182/11017 [01:28<1:26:21,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 183/11017 [01:28<1:26:25,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 184/11017 [01:29<1:26:24,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 185/11017 [01:29<1:26:19,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 186/11017 [01:30<1:26:14,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 187/11017 [01:30<1:26:18,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 188/11017 [01:31<1:26:14,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 189/11017 [01:31<1:26:07,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 190/11017 [01:32<1:26:03,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 191/11017 [01:32<1:26:02,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 192/11017 [01:33<1:26:07,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 193/11017 [01:33<1:26:09,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 194/11017 [01:34<1:26:07,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 195/11017 [01:34<1:26:07,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 196/11017 [01:35<1:26:04,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 197/11017 [01:35<1:26:06,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 198/11017 [01:36<1:26:07,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 199/11017 [01:36<1:26:08,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 200/11017 [01:37<1:26:06,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 201/11017 [01:37<1:26:03,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 202/11017 [01:37<1:26:04,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 203/11017 [01:38<1:26:05,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 204/11017 [01:38<1:26:04,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 205/11017 [01:39<1:26:03,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 206/11017 [01:39<1:26:08,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 207/11017 [01:40<1:26:08,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 208/11017 [01:40<1:26:11,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 209/11017 [01:41<1:26:05,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 210/11017 [01:41<1:26:02,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 211/11017 [01:42<1:25:58,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 212/11017 [01:42<1:25:55,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 213/11017 [01:43<1:25:58,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 214/11017 [01:43<1:25:56,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 215/11017 [01:44<1:25:55,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 216/11017 [01:44<1:25:53,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 217/11017 [01:45<1:25:53,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 218/11017 [01:45<1:25:51,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 219/11017 [01:46<1:25:49,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 220/11017 [01:46<1:25:51,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 221/11017 [01:47<1:25:50,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 222/11017 [01:47<1:25:52,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 223/11017 [01:47<1:25:51,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 224/11017 [01:48<1:25:50,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 225/11017 [01:48<1:25:50,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 226/11017 [01:49<1:25:51,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 227/11017 [01:49<1:25:47,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 228/11017 [01:50<1:25:48,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 229/11017 [01:50<1:25:50,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 230/11017 [01:51<1:25:50,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 231/11017 [01:51<1:26:03,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 232/11017 [01:52<1:25:55,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 233/11017 [01:52<1:25:53,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 234/11017 [01:53<1:25:52,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 235/11017 [01:53<1:25:54,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 236/11017 [01:54<1:25:55,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 237/11017 [01:54<1:25:56,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 238/11017 [01:55<1:25:48,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 239/11017 [01:55<1:25:44,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 240/11017 [01:56<1:25:42,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 241/11017 [01:56<1:25:42,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 242/11017 [01:57<1:25:38,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 243/11017 [01:57<1:25:35,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 244/11017 [01:58<1:25:36,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 245/11017 [01:58<1:25:40,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 246/11017 [01:58<1:25:38,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 247/11017 [01:59<1:25:39,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 248/11017 [01:59<1:25:36,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 249/11017 [02:00<1:25:34,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 250/11017 [02:00<1:25:34,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 251/11017 [02:01<1:25:36,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 252/11017 [02:01<1:25:32,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 253/11017 [02:02<1:25:37,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 254/11017 [02:02<1:25:38,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 255/11017 [02:03<1:25:38,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 256/11017 [02:03<1:25:33,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 257/11017 [02:04<1:25:32,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 258/11017 [02:04<1:25:31,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 259/11017 [02:05<1:25:37,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 260/11017 [02:05<1:25:44,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 261/11017 [02:06<1:25:39,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 262/11017 [02:06<1:25:39,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 263/11017 [02:07<1:25:44,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 264/11017 [02:07<1:25:37,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 265/11017 [02:08<1:25:34,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 266/11017 [02:08<1:25:34,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 267/11017 [02:09<1:25:33,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 268/11017 [02:09<1:25:34,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 269/11017 [02:09<1:25:28,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 270/11017 [02:10<1:25:25,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 271/11017 [02:10<1:25:27,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 272/11017 [02:11<1:25:28,  2.09it/s]\u001b[A\n",
            "Iteration:   2% 273/11017 [02:11<1:25:26,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 274/11017 [02:12<1:25:24,  2.10it/s]\u001b[A\n",
            "Iteration:   2% 275/11017 [02:12<1:25:24,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 276/11017 [02:13<1:25:29,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 277/11017 [02:13<1:25:24,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 278/11017 [02:14<1:25:30,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 279/11017 [02:14<1:25:34,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 280/11017 [02:15<1:25:31,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 281/11017 [02:15<1:25:30,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 282/11017 [02:16<1:25:29,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 283/11017 [02:16<1:25:27,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 284/11017 [02:17<1:25:25,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 285/11017 [02:17<1:25:20,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 286/11017 [02:18<1:25:22,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 287/11017 [02:18<1:25:20,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 288/11017 [02:19<1:25:22,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 289/11017 [02:19<1:25:17,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 290/11017 [02:19<1:25:21,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 291/11017 [02:20<1:25:19,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 292/11017 [02:20<1:25:18,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 293/11017 [02:21<1:25:19,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 294/11017 [02:21<1:25:18,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 295/11017 [02:22<1:25:17,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 296/11017 [02:22<1:25:14,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 297/11017 [02:23<1:25:16,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 298/11017 [02:23<1:25:15,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 299/11017 [02:24<1:25:13,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 300/11017 [02:24<1:25:18,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 301/11017 [02:25<1:25:16,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 302/11017 [02:25<1:25:13,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 303/11017 [02:26<1:25:14,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 304/11017 [02:26<1:25:16,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 305/11017 [02:27<1:25:19,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 306/11017 [02:27<1:25:20,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 307/11017 [02:28<1:25:21,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 308/11017 [02:28<1:25:15,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 309/11017 [02:29<1:25:14,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 310/11017 [02:29<1:25:13,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 311/11017 [02:30<1:25:12,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 312/11017 [02:30<1:25:12,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 313/11017 [02:30<1:25:11,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 314/11017 [02:31<1:25:17,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 315/11017 [02:31<1:25:13,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 316/11017 [02:32<1:25:13,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 317/11017 [02:32<1:25:12,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 318/11017 [02:33<1:25:12,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 319/11017 [02:33<1:25:08,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 320/11017 [02:34<1:25:10,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 321/11017 [02:34<1:25:06,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 322/11017 [02:35<1:25:05,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 323/11017 [02:35<1:25:02,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 324/11017 [02:36<1:25:00,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 325/11017 [02:36<1:24:58,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 326/11017 [02:37<1:24:56,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 327/11017 [02:37<1:24:55,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 328/11017 [02:38<1:24:59,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 329/11017 [02:38<1:24:57,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 330/11017 [02:39<1:25:01,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 331/11017 [02:39<1:25:02,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 332/11017 [02:40<1:24:58,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 333/11017 [02:40<1:24:56,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 334/11017 [02:40<1:24:57,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 335/11017 [02:41<1:24:57,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 336/11017 [02:41<1:25:00,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 337/11017 [02:42<1:25:00,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 338/11017 [02:42<1:24:55,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 339/11017 [02:43<1:24:58,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 340/11017 [02:43<1:25:06,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 341/11017 [02:44<1:25:01,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 342/11017 [02:44<1:24:56,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 343/11017 [02:45<1:24:54,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 344/11017 [02:45<1:24:55,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 345/11017 [02:46<1:24:55,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 346/11017 [02:46<1:24:54,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 347/11017 [02:47<1:24:54,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 348/11017 [02:47<1:24:51,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 349/11017 [02:48<1:24:49,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 350/11017 [02:48<1:24:48,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 351/11017 [02:49<1:24:47,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 352/11017 [02:49<1:24:51,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 353/11017 [02:50<1:24:46,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 354/11017 [02:50<1:24:55,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 355/11017 [02:51<1:24:57,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 356/11017 [02:51<1:24:55,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 357/11017 [02:51<1:24:53,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 358/11017 [02:52<1:24:55,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 359/11017 [02:52<1:24:49,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 360/11017 [02:53<1:24:45,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 361/11017 [02:53<1:24:49,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 362/11017 [02:54<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 363/11017 [02:54<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 364/11017 [02:55<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 365/11017 [02:55<1:24:45,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 366/11017 [02:56<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 367/11017 [02:56<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 368/11017 [02:57<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 369/11017 [02:57<1:24:42,  2.10it/s]\u001b[A\n",
            "Iteration:   3% 370/11017 [02:58<1:24:44,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 371/11017 [02:58<1:24:48,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 372/11017 [02:59<1:24:44,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 373/11017 [02:59<1:24:45,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 374/11017 [03:00<1:24:48,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 375/11017 [03:00<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 376/11017 [03:01<1:24:53,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 377/11017 [03:01<1:25:00,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 378/11017 [03:02<1:24:55,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 379/11017 [03:02<1:24:50,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 380/11017 [03:02<1:24:47,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 381/11017 [03:03<1:24:42,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 382/11017 [03:03<1:24:46,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 383/11017 [03:04<1:24:40,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 384/11017 [03:04<1:24:37,  2.09it/s]\u001b[A\n",
            "Iteration:   3% 385/11017 [03:05<1:24:36,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 386/11017 [03:05<1:24:39,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 387/11017 [03:06<1:24:40,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 388/11017 [03:06<1:24:38,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 389/11017 [03:07<1:24:38,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 390/11017 [03:07<1:24:37,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 391/11017 [03:08<1:24:43,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 392/11017 [03:08<1:24:42,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 393/11017 [03:09<1:24:36,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 394/11017 [03:09<1:24:32,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 395/11017 [03:10<1:24:32,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 396/11017 [03:10<1:24:31,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 397/11017 [03:11<1:24:27,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 398/11017 [03:11<1:24:23,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 399/11017 [03:12<1:24:27,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 400/11017 [03:12<1:24:26,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 401/11017 [03:12<1:24:29,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 402/11017 [03:13<1:24:27,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 403/11017 [03:13<1:24:24,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 404/11017 [03:14<1:24:26,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 405/11017 [03:14<1:24:23,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 406/11017 [03:15<1:24:26,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 407/11017 [03:15<1:24:24,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 408/11017 [03:16<1:24:23,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 409/11017 [03:16<1:24:19,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 410/11017 [03:17<1:24:20,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 411/11017 [03:17<1:24:27,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 412/11017 [03:18<1:24:24,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 413/11017 [03:18<1:24:26,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 414/11017 [03:19<1:24:20,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 415/11017 [03:19<1:24:26,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 416/11017 [03:20<1:24:25,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 417/11017 [03:20<1:24:19,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 418/11017 [03:21<1:24:18,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 419/11017 [03:21<1:24:19,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 420/11017 [03:22<1:24:18,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 421/11017 [03:22<1:24:22,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 422/11017 [03:23<1:24:17,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 423/11017 [03:23<1:24:12,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 424/11017 [03:23<1:24:14,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 425/11017 [03:24<1:24:10,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 426/11017 [03:24<1:24:08,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 427/11017 [03:25<1:24:14,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 428/11017 [03:25<1:24:27,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 429/11017 [03:26<1:24:23,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 430/11017 [03:26<1:24:21,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 431/11017 [03:27<1:24:25,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 432/11017 [03:27<1:24:23,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 433/11017 [03:28<1:24:19,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 434/11017 [03:28<1:24:14,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 435/11017 [03:29<1:24:09,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 436/11017 [03:29<1:24:06,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 437/11017 [03:30<1:24:12,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 438/11017 [03:30<1:24:08,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 439/11017 [03:31<1:24:09,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 440/11017 [03:31<1:24:09,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 441/11017 [03:32<1:24:11,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 442/11017 [03:32<1:24:05,  2.10it/s]\u001b[A\n",
            "Iteration:   4% 443/11017 [03:33<1:24:08,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 444/11017 [03:33<1:24:09,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 445/11017 [03:34<1:24:10,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 446/11017 [03:34<1:24:06,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 447/11017 [03:34<1:24:09,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 448/11017 [03:35<1:24:05,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 449/11017 [03:35<1:24:04,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 450/11017 [03:36<1:24:08,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 451/11017 [03:36<1:24:07,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 452/11017 [03:37<1:24:07,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 453/11017 [03:37<1:24:03,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 454/11017 [03:38<1:24:02,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 455/11017 [03:38<1:24:07,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 456/11017 [03:39<1:24:02,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 457/11017 [03:39<1:24:01,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 458/11017 [03:40<1:24:04,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 459/11017 [03:40<1:24:04,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 460/11017 [03:41<1:23:59,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 461/11017 [03:41<1:24:01,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 462/11017 [03:42<1:23:58,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 463/11017 [03:42<1:24:03,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 464/11017 [03:43<1:23:59,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 465/11017 [03:43<1:23:58,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 466/11017 [03:44<1:23:56,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 467/11017 [03:44<1:23:57,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 468/11017 [03:44<1:23:56,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 469/11017 [03:45<1:23:58,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 470/11017 [03:45<1:24:02,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 471/11017 [03:46<1:24:01,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 472/11017 [03:46<1:24:03,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 473/11017 [03:47<1:23:58,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 474/11017 [03:47<1:23:56,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 475/11017 [03:48<1:23:58,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 476/11017 [03:48<1:23:56,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 477/11017 [03:49<1:23:52,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 478/11017 [03:49<1:23:51,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 479/11017 [03:50<1:24:03,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 480/11017 [03:50<1:24:05,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 481/11017 [03:51<1:24:03,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 482/11017 [03:51<1:24:00,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 483/11017 [03:52<1:23:53,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 484/11017 [03:52<1:23:52,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 485/11017 [03:53<1:23:54,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 486/11017 [03:53<1:23:54,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 487/11017 [03:54<1:23:54,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 488/11017 [03:54<1:23:50,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 489/11017 [03:55<1:23:54,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 490/11017 [03:55<1:23:55,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 491/11017 [03:55<1:23:50,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 492/11017 [03:56<1:23:47,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 493/11017 [03:56<1:23:44,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 494/11017 [03:57<1:23:47,  2.09it/s]\u001b[A\n",
            "Iteration:   4% 495/11017 [03:57<1:23:49,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 496/11017 [03:58<1:23:47,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 497/11017 [03:58<1:23:45,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 498/11017 [03:59<1:23:41,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 499/11017 [03:59<1:23:43,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 500/11017 [04:00<1:23:43,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 501/11017 [04:00<1:23:47,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 502/11017 [04:01<1:23:47,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 503/11017 [04:01<1:23:48,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 504/11017 [04:02<1:23:43,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 505/11017 [04:02<1:23:43,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 506/11017 [04:03<1:23:46,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 507/11017 [04:03<1:23:45,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 508/11017 [04:04<1:23:42,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 509/11017 [04:04<1:23:37,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 510/11017 [04:05<1:23:38,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 511/11017 [04:05<1:23:40,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 512/11017 [04:06<1:23:40,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 513/11017 [04:06<1:23:39,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 514/11017 [04:06<1:23:42,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 515/11017 [04:07<1:23:42,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 516/11017 [04:07<1:23:37,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 517/11017 [04:08<1:23:35,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 518/11017 [04:08<1:23:35,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 519/11017 [04:09<1:23:40,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 520/11017 [04:09<1:23:41,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 521/11017 [04:10<1:23:43,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 522/11017 [04:10<1:23:44,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 523/11017 [04:11<1:23:48,  2.09it/s]\u001b[A\n",
            "Iteration:   5% 524/11017 [04:11<1:23:42,  2.09it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"transformers/examples/run_squad.py\", line 830, in <module>\n",
            "    main()\n",
            "  File \"transformers/examples/run_squad.py\", line 769, in main\n",
            "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
            "  File \"transformers/examples/run_squad.py\", line 235, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 166, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JCNRkQwUD56",
        "colab_type": "text"
      },
      "source": [
        "## 3.0 Setup prediction code\n",
        "\n",
        "Now we can use the Hugging Face library to make predictions using our newly trained model. Note that a lot of the code is pulled from `run_squad.py` in the Hugging Face repository, with all the training parts removed. This modified code allows to run predictions we pass in directly as strings, rather .json format like the training/test set.\n",
        "\n",
        "NOTE if you decided train your own mode, change the flag `use_own_model` to `True`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp0Pq9z9Y4S0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "814460e6c2ea47fd9d0f10ea0bdfa5b8",
            "7b61b9db26d2435c950dac4efaaa5110",
            "dd7e54b1368346a29e1b963b6b410df2",
            "0df477b5255d4bb18305cb27d1dd72b9",
            "70b0ff61b96d433b831b15ceccae702d",
            "97187d875ed84185a938a9a983cf4fc8",
            "f9e002990e3a44de86579377f9fe24f6",
            "714017c3802f4b4c97b46843000a38b2",
            "e53e5b79e1fa460fad9e8c2f41bcacaf",
            "50759731043349f6bdc38656c25efa46",
            "8ac52bdfe27f4600b5b48a37fe608908",
            "9169a9b8d6974aa8ab759d9b8dbbbba1",
            "616193b0be9c4177b3df480b7205e9ef",
            "ab6f1b08894145c59eecdb63fd4efc24",
            "63c9766c59324c32899e6a0ddd9dcd39",
            "b0b013efa73945a4abdbe13101596e29",
            "f522afc051ab4e98aaa7444592a1d98a",
            "8f1526b1dd324118b4faff49132fc646",
            "63e48b35866d4b05a9cce5549b392a88",
            "464ba8f4d6814f198c0971f64254ca53",
            "b3363a1685344020ba3442bda67fa0d3",
            "b1a6393f5c8c4d10b67498e51a64ec55",
            "b7cb247067664b1498d79ee320d359e3",
            "db4997c677084a8bb1fe8d0f921bcaff"
          ]
        },
        "cellView": "code",
        "outputId": "5ac36450-0db0-42f4-cf85-3b33b35fb33b"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features\n",
        ")\n",
        "\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
        "\n",
        "# READER NOTE: Set this flag to use own model, or use pretrained model in the Hugging Face repository\n",
        "use_own_model = False\n",
        "\n",
        "if use_own_model:\n",
        "  model_name_or_path = \"/content/model_output\"\n",
        "else:\n",
        "  model_name_or_path = \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "\n",
        "output_dir = \"\"\n",
        "\n",
        "# Config\n",
        "n_best_size = 1\n",
        "max_answer_length = 30\n",
        "do_lower_case = True\n",
        "null_score_diff_threshold = 0.0\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "\n",
        "# Setup model\n",
        "config_class, model_class, tokenizer_class = (\n",
        "    AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer)\n",
        "config = config_class.from_pretrained(model_name_or_path)\n",
        "tokenizer = tokenizer_class.from_pretrained(\n",
        "    model_name_or_path, do_lower_case=True)\n",
        "model = model_class.from_pretrained(model_name_or_path, config=config)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "processor = SquadV2Processor()\n",
        "\n",
        "def run_prediction(question_texts, context_text):\n",
        "    \"\"\"Setup function to compute predictions\"\"\"\n",
        "    examples = []\n",
        "\n",
        "    for i, question_text in enumerate(question_texts):\n",
        "        example = SquadExample(\n",
        "            qas_id=str(i),\n",
        "            question_text=question_text,\n",
        "            context_text=context_text,\n",
        "            answer_text=None,\n",
        "            start_position_character=None,\n",
        "            title=\"Predict\",\n",
        "            is_impossible=False,\n",
        "            answers=None,\n",
        "        )\n",
        "\n",
        "        examples.append(example)\n",
        "\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "            }\n",
        "\n",
        "            example_indices = batch[3]\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                unique_id = int(eval_feature.unique_id)\n",
        "\n",
        "                output = [to_list(output[i]) for output in outputs]\n",
        "\n",
        "                start_logits, end_logits = output\n",
        "                result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                all_results.append(result)\n",
        "\n",
        "    output_prediction_file = \"predictions.json\"\n",
        "    output_nbest_file = \"nbest_predictions.json\"\n",
        "    output_null_log_odds_file = \"null_predictions.json\"\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size,\n",
        "        max_answer_length,\n",
        "        do_lower_case,\n",
        "        output_prediction_file,\n",
        "        output_nbest_file,\n",
        "        output_null_log_odds_file,\n",
        "        False,  # verbose_logging\n",
        "        True,  # version_2_with_negative\n",
        "        null_score_diff_threshold,\n",
        "        tokenizer,\n",
        "    )\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "814460e6c2ea47fd9d0f10ea0bdfa5b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=1114, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e53e5b79e1fa460fad9e8c2f41bcacaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=760289, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f522afc051ab4e98aaa7444592a1d98a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=234922444, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIQOB8vhpcKs",
        "colab_type": "text"
      },
      "source": [
        "## 4.0 Run predictions\n",
        "\n",
        "Now for the fun part... testing out your model on different inputs. Pretty rudimentary example here. But the possibilities are endless with this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-sUrcA5nXTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "cellView": "code",
        "outputId": "bd56ff67-50b1-4306-ffd8-f56e538dead4"
      },
      "source": [
        "context = \"My favourite colour is blue\"\n",
        "questions = [\"What's your favourite colour?\"]\n",
        "\n",
        "# Run method\n",
        "predictions = run_prediction(questions, context)\n",
        "\n",
        "# Print results\n",
        "for key in predictions.keys():\n",
        "  print(predictions[key])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 473.34it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 3844.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "blue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkivu8FOqp_8",
        "colab_type": "text"
      },
      "source": [
        "## 5.0 Next Steps\n",
        "\n",
        "In this tutorial, you learnt how to fine-tune an ALBERT model for the task of question answering, using the SQuAD dataset. Then, you learnt how you can make predictions using the model. \n",
        "\n",
        "We retrofitted `compute_predictions_logits` to make the prediction for the purpose of simplicity and minimising dependencies in the tutorial. Take a peak inside that module to see how it works. If you want to serve this as an API, you will want to strip out a lot of the stuff it's doing (such as writing the predictions to a JSON, etc)\n",
        "\n",
        "You can now turn this into an API by serving it using a web framework. I recommend checking out FastAPI, which is what [Albert Learns to Read](https://littlealbert.now.sh) is built on. \n",
        "\n",
        "Feel free to tweet me on @techno246 if you have any questions!"
      ]
    }
  ]
}